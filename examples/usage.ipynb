{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `d:\\projects_julia\\jul-project\\DecisionTrees\\examples`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "using Revise\n",
    "using DecisionTrees\n",
    "using Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data initialization\n",
    "\n",
    "Construct input matrix `X` of size `n x m` with `n` samples each with `m` features.\n",
    "The features are allowed to be of type `Real`, `String` or `Bool`.\n",
    "Also create vector of labels `Y` corresponding to sampels.\n",
    "\n",
    "This can be achieved manually, like below, or by using functions provided\n",
    "in file [data.jl](), like in [examples/titanic.ipynb]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    -1.5  \"a\"     1 true; \n",
    "    -1.14 \"b\"     5 false; \n",
    "    -0.45 \"bb\"   -8 false; \n",
    "     2.5  \"aaa\"  -1 true; \n",
    "    27.4  \"aaaa\"  5 true]\n",
    "Y = [0, 1, 0, 1, 1];"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, empty struct `DecisionTree` must be initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision tree\n",
       "    Maximal depth: nothing\n",
       "    Attribute count: nothing\n",
       "\n",
       "    Nodes:\n",
       "        Leaf node:  \n",
       "        Decision: nothing  \n",
       "        Confidence: nothing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling function `learn!` the decision tree is build to maximize information\n",
    "gain in each split node for input data pair `X`, `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision tree\n",
       "    Maximal depth: 1000\n",
       "    Attribute count: 4\n",
       "\n",
       "    Nodes:\n",
       "        Decision node\n",
       "        Type: real\n",
       "        Parameter index: 1\n",
       "        θ: 1.025\n",
       "    \n",
       "        Decision node\n",
       "            Type: stringequality\n",
       "            Parameter index: 2\n",
       "            θ: b\n",
       "    \n",
       "            Leaf node:  \n",
       "                Decision: 1  \n",
       "                Confidence: 1.0\n",
       "            Leaf node:  \n",
       "                Decision: 0  \n",
       "                Confidence: 1.0\n",
       "        Leaf node:  \n",
       "            Decision: 1  \n",
       "            Confidence: 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn!(dt, X, Y)\n",
    "dt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are then predicted by calling function `evaluate`.\n",
    "Because the maximal depth of decision tree is very high the train error should\n",
    "be 0.0 if working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.0\n"
     ]
    }
   ],
   "source": [
    "Y_ = evaluate(dt, X)\n",
    "println(\"Train error: $(mean(Y .!= Y_))\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning attributes\n",
    "- __depth__: Sets the maximal possible depth of build decision tree.\n",
    "When the depth is limited enought the train error becomes larger than 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision tree\n",
       "    Maximal depth: 1\n",
       "    Attribute count: 4\n",
       "\n",
       "    Nodes:\n",
       "        Decision node\n",
       "        Type: real\n",
       "        Parameter index: 3\n",
       "        θ: 3.0\n",
       "    \n",
       "        Leaf node:  \n",
       "            Decision: 0  \n",
       "            Confidence: 0.6666666666666666\n",
       "        Leaf node:  \n",
       "            Decision: 1  \n",
       "            Confidence: 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_d = DecisionTree()\n",
    "learn!(dt_d, X, Y; depth=1)\n",
    "dt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.2\n"
     ]
    }
   ],
   "source": [
    "Y_ = evaluate(dt_d, X)\n",
    "println(\"Train error: $(mean(Y .!= Y_))\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __attribute_count__: Sets the number of randomly selected features which are\n",
    "considered for optimal split.\n",
    "When the attribute count is set lower than the total number of features\n",
    "the decision tree becomes undeterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision tree\n",
       "    Maximal depth: 1000\n",
       "    Attribute count: 1\n",
       "\n",
       "    Nodes:\n",
       "        Decision node\n",
       "        Type: real\n",
       "        Parameter index: 1\n",
       "        θ: 1.025\n",
       "    \n",
       "        Decision node\n",
       "            Type: real\n",
       "            Parameter index: 1\n",
       "            θ: -1.3199999999999998\n",
       "    \n",
       "            Leaf node:  \n",
       "                Decision: 0  \n",
       "                Confidence: 1.0\n",
       "            Leaf node:  \n",
       "                Decision: 0  \n",
       "                Confidence: 0.5\n",
       "        Leaf node:  \n",
       "            Decision: 1  \n",
       "            Confidence: 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_a = DecisionTree()\n",
    "learn!(dt_a, X, Y; attribute_count=1)\n",
    "dt_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.2\n"
     ]
    }
   ],
   "source": [
    "Y_ = evaluate(dt_a, X)\n",
    "println(\"Train error: $(mean(Y .!= Y_))\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is model which combines several undeterministically constructed\n",
    "decision trees and produces result by averaging their decision.\n",
    "\n",
    "Fistly, the empty struct `RandomForest` must be initialized with single argument\n",
    "__size__ which describes the amount of used `DecisionTree`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest\n",
       "    Tree count: 10\n",
       "    Bagging: false\n",
       "    \n",
       "    Each tree:\n",
       "        Maximal depth: nothing\n",
       "        Attribute count: nothing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForest(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `learn!` constructs all trees in random forest.\n",
    "Decision trees are build the same as in model `DecisionTree` and thus the same \n",
    "learning arguments are aviable (`depth`, `attribute_count`).\n",
    "The learning might take a while, thus the progress bar is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mProgress:  20%|█████████                                |  ETA: 0:00:02\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Random Forest\n",
       "    Tree count: 10\n",
       "    Bagging: false\n",
       "    \n",
       "    Each tree:\n",
       "        Maximal depth: 1000\n",
       "        Attribute count: 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn!(rf, X, Y)\n",
    "rf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are predicted by calling function `evaluate`.\n",
    "Once again, when all trees of the forest are deterministic the train error is\n",
    "0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.0\n"
     ]
    }
   ],
   "source": [
    "Y_ = evaluate(rf, X)\n",
    "println(\"Train error: $(mean(Y .!= Y_))\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning attributes\n",
    "- __bagging__: When set to `true` each tree is trained with different dataset\n",
    "with the same size as the input dataset which was generated by randomly sampling\n",
    "with replacemnt from it.\n",
    "This also produces nondeterministic behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random Forest\n",
       "    Tree count: 10\n",
       "    Bagging: true\n",
       "    \n",
       "    Each tree:\n",
       "        Maximal depth: 1000\n",
       "        Attribute count: 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_b = RandomForest(10)\n",
    "learn!(rf_b, X, Y; bagging=true)\n",
    "rf_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.0\n"
     ]
    }
   ],
   "source": [
    "Y_ = evaluate(rf_b, X)\n",
    "println(\"Train error: $(mean(Y .!= Y_))\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
